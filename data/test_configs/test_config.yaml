use_gpu: true
model_parameters:
  test_gnn:
    input_dim: 10
    hidden_dim: 16
    output_dim: 3
training_parameters:
  batch_size: 1
  test_split: 0.2
  epochs: 100
  learning_rate: 0.003
  #lr_scheduler_params:
  #  scheduler: "ReduceLROnPlateau" # Options: "ReduceLROnPlateau", "CyclicLR", "OneCycleLR"
  #  params: # Give the parameters for the specific class you chose. Here you can find the documentation: https://pytorch.org/docs/stable/optim.html
  #    mode: "min"
  loss: "crossentropy" # Options: "mse", "rmse", "rmsle"
  optimizer: "adam" # Options: "adam", "sgd"
  weight_decay: 0.0
  momentum: 0.1
  seed: 42
  batch_shuffle: false
  patience: 10000
  log_image_frequency: 5
pre_processing_parameters:
  coordinate_transformation:
    reference_point_annotation:
      x: 16038.24
      y: 69265.17
    reference_point_image:
      x: 380
      y: 1001
    rotation: 90
    mirror_x: false # Mirror the image over the y-axis
    mirror_y: false # Mirror the image over the x-axis
    magnification: 0.0625
dataset_parameters:
  class_attributes:
    class_name: "graph_dataset"
    root: "/home/dascim/repos/histograph/data/input"
    raw_file_name: "test_data.csv"
    test_split: 0.2
  process: true
  input_paths:
    feature_dir: "/home/dascim/repos/from_odyssee/resultats/features/"
    df_matchings: '/home/dascim/repos/from_odyssee/resultats/matching_across_stainings_001_from_segmentation.npy'
    df_centroids: '/home/dascim/repos/from_odyssee/resultats/IFTA_EXC_001_25_centroids_from_gt.npy'
    df_annotations: '/home/dascim/repos/histograph/data/input/annotations_exc.csv'
  feature_list:
    - 'tcell _25_in'
    - 'tcell _25_out'
    - 'cd68_in'
    - 'cd163_in'
    - 'cd206_in'
    - 'ms4a4a_in'
    - 'cd68_out'
    - 'cd163_out'
    - 'cd206_out'
    - 'ms4a4a_out'
